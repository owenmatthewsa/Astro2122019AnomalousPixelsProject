{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports. This contains some imports not required for this notebook. \n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import pylab                   # Needed to plot histograms.\n",
    "from astropy.io import fits                    # Need this if you want to use astropy.io io objects.\n",
    "from astropy.stats import mad_std              # The median absolute deviation, a more robust estimator than std.\n",
    "from PIL import Image\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import signal\n",
    "\n",
    "'''Filter out warnings. May or may not need this. But shouldn't hurt to put it in.\n",
    "This is the \"new\" code for avoiding warnings-- seems to work better. Copied from an SDSS notebook.'''\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append(r'C:\\Users\\owenm\\Documents\\ASTR 21200 2019\\Software\\a212pylibs\\datapype')\n",
    "\n",
    "from datafits import DataFits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the data directory.\n",
    "# datapath = '/Users/alex/_observing/24-inch/2018/manual_dark/darks_180420'\n",
    "datapath = r'C:\\Users\\owenm\\Documents\\ASTR 21200 2019\\Data\\Project\\dark'\n",
    "savepath = r'C:\\Users\\owenm\\Documents\\ASTR 21200 2019\\Data\\BadPixelsFitss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List files in the the data directory.\n",
    "\n",
    "whichpath = datapath\n",
    "\n",
    "## For ALL the files in the directory.\n",
    "# allfiles = [f for f in os.listdir(datapath)]\n",
    "\n",
    "## Various list comprehensions can pick out files with particular characteristics.\n",
    "allfiles = [f for f in os.listdir(whichpath) if '.fit' in f and ('bias.' in f) and 'mdark' not in f]\n",
    "\n",
    "allfiles = sorted(allfiles)       ## This is necessary on my Mac, may not be for others?\n",
    "for i in range(len(allfiles)):\n",
    "    print( i, allfiles[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct a list of files you wish to view and/or process.\n",
    "\n",
    "acceptlist = True             # True if you want to accept all the files in allfiles.\n",
    "contiguous = True             # True if you want to accept a contiguous subset of allfiles.\n",
    "startfile, endfile = 0,9      # The first and last files in a contiquous subset.\n",
    "flist = [0,3,4,5,6,7,8]        # An explicit list of the files you want to accept.\n",
    "\n",
    "if acceptlist == True:\n",
    "    files = allfiles\n",
    "    for i in range(len(files)):\n",
    "        print(i, files[i])\n",
    "else:\n",
    "    if contiguous == True:\n",
    "        files = allfiles[startfile:endfile+1]\n",
    "        for i in range(len(files)):\n",
    "            print( i, files[i])\n",
    "    else:\n",
    "        files = []\n",
    "        for i in range(len(flist)):\n",
    "            files.append(allfiles[flist[i]])\n",
    "        for i in range(len(files)):\n",
    "            print( i, flist[i], files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1. Creating Faulty Non-Noisy Pixels Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Make a stack of images, a list of headers from those images, and calculate some medians and stds\n",
    "that will help set autoscaling parameters.'''\n",
    "\n",
    "\n",
    "image = np.zeros((len(files), 1024,1024))\n",
    "imedian = np.zeros((len(files)))          \n",
    "istd = np.zeros((len(files)))              \n",
    "madstd = np.zeros((len(files))) \n",
    "headlist = []  \n",
    "print('image.shape =', image.shape)\n",
    "for i in range(len(files)):\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "    # Use this code block if you want to use the standard astropy.io package.\n",
    "    fitsfilename = os.path.join(datapath, files[i])    # Full path to a fitsfile.\n",
    "    hdulist = fits.open(fitsfilename)                  # Open a fits file as an hdulist object.\n",
    "    hdu0 = hdulist[0]                                  # Define a fits object as the 0th hdu in the fitsfile.\n",
    "    image[i] = hdu0.data * 1.0                         # Define image in stack as float of data in the 0th hdu.\n",
    "    headlist.append(hdu0.header)                       # Append the header of the fits object to the header list.\n",
    "    print('')\n",
    "    print(i,files[i])\n",
    "###############################################################################    \n",
    "    \n",
    "    ## Calculate some medians and stds to use in autoscaling that aren't unduly biased by extreme values.\n",
    "    ## Optionally, print out masked and unmasked values to explore the effects of extreme values on the statistics.\n",
    "    \n",
    "    madstd[i] = mad_std(image[i],ignore_nan=True)\n",
    "    imedian[i] = np.nanmedian(image[i])\n",
    "    istd[i] = np.nanstd(image[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = 0\n",
    "for i in range(len(image)):\n",
    "    istand = image[i] - imedian[i]\n",
    "    bad += (istand > istd[i])\n",
    "    bad += (istand < -istd[i])\n",
    "for j in range(len(sum(bad))):\n",
    "    print(str(j) + ':' + str(sum(bad)[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a map of how often the pixels have been bad\n",
    "\n",
    "bads = np.zeros((1024,1024))\n",
    "\n",
    "imedian2 = np.zeros((len(files)))           # 1D numpy array to hold array medians.\n",
    "istd2 = np.zeros((len(files)))              # 1D numpy array to hold array stds.\n",
    "\n",
    "for i in range(len(files)):\n",
    "    imedian2[i] = np.nanmedian(image[i,200:,:])\n",
    "    istd2[i] = np.nanstd(image[i,200:,:])\n",
    "    #sets the median and std arrays to hold the median and std of each image\n",
    "\n",
    "for i in range(len(image)):\n",
    "    istand = image[i] - imedian2[i]\n",
    "    bad1 = (istand > istd2[i]) * 1\n",
    "    #check if 1 standard deviation above the median\n",
    "    bad2 = (istand < -istd2[i]) * 1\n",
    "    #check if 1 standard deviation below the median\n",
    "    bad = bad1 + bad2\n",
    "    #will be 1 if one standard deviation off (above or below), 0 otherwise\n",
    "    bads += bad\n",
    "#counts the number\n",
    "\n",
    "#print(bads)\n",
    "#print(bads[:,1:])\n",
    "b = bads[:, 200:]\n",
    "print(b)\n",
    "pix = np.zeros((1024,824))\n",
    "ctr = 0\n",
    "for i in range(1024):\n",
    "    for j in range(824):\n",
    "        if b[i,j] >= 20:\n",
    "            ctr += 1\n",
    "            pix[i,j] = 1\n",
    "            #print(i,j)\n",
    "#checks number of images for which a pixel is in \"bads\"\n",
    "#if  >20 times bad, sets the pixel's corresponding point in \"pix\" to 1\n",
    "            \n",
    "print(str(ctr/(1024 * 824)))\n",
    "#gives ratio of flaged pixels to all pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above array gives the number of times, for each pixel, it has been deemed \"bad\" in the list of 300 darks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check pixels that have been bad at least once: 49.2% of pixels meet this criteria If we check pixels that have been bad at least twice: 18.5% of pixels meet this criteria If we check pixels that have been bad at least 3 times: 8.28% of pixels meet this criteria If we check pixels that have been bad at least 4 times: 5.21% of pixels meet this criteria ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code makes list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pix3 = np.zeros((1024,824))\n",
    "#makes 2D a zero array that will become our final list of pixels to smooth over\n",
    "mask3 = np.zeros((len(files),1024,824))\n",
    "#zero array that will become a stack of masks\n",
    "for i in range(1024):\n",
    "    for j in range(824):\n",
    "        if pix[i,j] == 1:\n",
    "        #checks if pixel has been flagged by first algorithm, ignore if not\n",
    "        #this next series of if statements considers several different possible pixel locations, with the goal of setting a \"sur\"\n",
    "        #\"sur\" is a 2D array that is basically the pixel values of the surronding area\n",
    "            if i >= 5 and i < 1019:\n",
    "                #all of these use a row value between 5 and 1019\n",
    "                if j >= 5 and j < 819:\n",
    "                    sur = image[:,i-5:i+5,200+j-5:200+j+5]\n",
    "                    #these pixels are in places where we can easily check the surronding area\n",
    "                elif j < 5:\n",
    "                    sur = np.append(image[:,i-5:i+5,200:200+j], image[:,i-5:i+5,-10+j:])\n",
    "                    #if in a colum <5, wraps around the side to fill in the rest of the neighborhood\n",
    "                else:\n",
    "                    sur = np.append(image[:,i-5:i+5,j:], image[:,i-5:i+5,200:210-1024+j])\n",
    "                    #column in last 5, wraps around to fill in rest of neighborhood\n",
    "            elif i < 5:\n",
    "                #all of these are for a row value less than 5\n",
    "                if j >= 5 and j < 819:\n",
    "                    sur = np.append(image[:,:i,200+j-5:200+j+5], image[:,-10+i:,200+j-5:200+j+5])\n",
    "                    #accaptable column value, only need to wrap around top-bottom (rows)\n",
    "                elif j < 5:\n",
    "                    sur = np.append(image[:,:i,200:200+j], image[:,-10+i:,-10+j:])\n",
    "                    #in a corner, wraps around to fill in both dimensions\n",
    "                else:\n",
    "                    sur = np.append(image[:,:i,j:], image[:,-10+i:,200:210-1024+j])\n",
    "                    #second corner\n",
    "            else:\n",
    "                #row values in the last 5\n",
    "                if j >= 5 and j < 819:\n",
    "                    sur = np.append(image[:,i:,200+j-5:200+j+5], image[:, :10-1024+i,200+j-5:200+j+5])\n",
    "                    #accaptable column value, only need to wrap around top-bottom (rows)\n",
    "                elif j < 5:\n",
    "                    sur = np.append(image[:,i:,200:200+j], image[:, :10-1024+i,-10+j:])\n",
    "                    #third corner, wrap around in both dimensions\n",
    "                else:\n",
    "                    sur = np.append(image[:,i:,j:], image[:, :10-1024+i,200:210-1024+j])\n",
    "                    #fourth corner\n",
    "            surmed = np.nanmedian(sur)\n",
    "            #sets surmed to median value of the surronding area\n",
    "            surstd = np.nanstd(sur)\n",
    "            #sets surstd to standard deviation of surronding area\n",
    "            pmed = np.nanmedian(image[:,i,200+j])\n",
    "            #finds the median value of the pixel accross all 32 images\n",
    "            pix3[i,j] = abs(surmed - pmed) > surstd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a median dark image from the image stack\n",
    "dark = np.nanmedian(image, axis=0)\n",
    "# make a bias file\n",
    "bias = dark.copy()\n",
    "\n",
    "# take a median row slice and smooth it\n",
    "rowslice = np.median(bias, axis=0)\n",
    "# smooth_rowslice = signal.medfilt(rowslice, kernel_size=5)\n",
    "# smooth_rowslice = signal.savgol_filter(smooth_rowslice, window_length=101, polyorder=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making initial mask\n",
    "for i in range(1024):\n",
    "    for j in range(824):          \n",
    "            # sets to 1 if the median pixel value is more than one standard deviation away from the median of the surronding area\n",
    "            if pix3[i,j] == 1:\n",
    "                mask3[:,i,j] = image[:,i,200+j] - rowslice[200+j]\n",
    "                #if pix3 is 1, sets the mask to be the value of the original image minus that value of the neighborhood median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masking for pix3 \n",
    "\n",
    "maskhelp2 = np.zeros((len(files),1024,200))\n",
    "mask6 = np.append(maskhelp2,mask3, axis=2)\n",
    "\n",
    "smoothed3 = image-mask6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO NOT RUN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display all the images in the stack.\n",
    "# figx, figy = 20,20   # Use these to reveal fine detail in images.\n",
    "figx, figy = 8,8   # Use these to get a quick look and save space.\n",
    "\n",
    "for i in range(len(files)):\n",
    "    plt.figure(figsize = (figx,figy))\n",
    "    vmx= imedian[i] + madstd[i] * 3.0\n",
    "    vmn = imedian[i] - madstd[i] * 3.0\n",
    "#     grid()\n",
    "    plt.title(files[i] + '   Median =' + str(imedian[i]) + '    mad_std =' + str(madstd[i]))\n",
    "    plt.imshow(smoothed[i],'gray',interpolation = 'nearest',vmax=vmx,vmin=vmn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating and saving dead pixels fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a workable data format for our boolean 2D Array\n",
    "hdumy = fits.PrimaryHDU(pix3)\n",
    "\n",
    "#Turning Workable Object into a fits\n",
    "outd = fits.HDUList([hdumy])\n",
    "\n",
    "## Construct a name and 'save directory' for the dark-subtracted, flatfielded image.\n",
    "outname = 'bad_pixels' + '(INSERT NUMBER OR OTHER THING!!!!! OR ITLL BREAK SOME STUFF) 5' + '.fits'\n",
    "outpath = savepath\n",
    "print('outpath =',outpath)\n",
    "outf = os.path.join(outpath,outname)\n",
    "print('outname =',outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now save the file (or not).\n",
    "print(outf)\n",
    "yes_or_no = input('Save file? Enter \"y\" or \"n\":')\n",
    "if yes_or_no == 'y':\n",
    "    outd.writeto(outf, overwrite = False)\n",
    "    print( outname + ' has been saved.')\n",
    "else:\n",
    "    print( 'OK-- file was not saved.')\n",
    "\n",
    "# outd.save(outf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 Creating Fits of Noisy Pixels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In dah_functions2 but my imports are being weird so i did it.\n",
    "def stackfits(whichpath,files):\n",
    "    '''\n",
    "    Make a stack of images, a list of headers from those images, and 1D arrays for medians and mad_stds.\n",
    "    whichpath:   The path to the fits files.\n",
    "    files:  A list of files.\n",
    "    '''\n",
    "\n",
    "    ## Load the header of the first file in the list \"files\".\n",
    "    df = DataFits()                                                   # Create a DataPype DataFits io object.\n",
    "    df.loadhead(os.path.join(whichpath,files[0]))                # Loads just the header of the first file.\n",
    "    ## Make variables for the numbers of rows and columns.\n",
    "    rows, cols = df.header['naxis2'], df.header['naxis1']\n",
    "    print('rows =',rows,'   cols =',cols)\n",
    "\n",
    "    image = np.zeros((len(files), rows,cols))  # 3D numpy array to hold the stack of images.\n",
    "    imedian = np.zeros((len(files)))           # 1D numpy array to hold array medians.\n",
    "    imad = np.zeros((len(files)))            # 1D numpy array to hold Median absolute deviations.\n",
    "\n",
    "    headlist = []                              # Empty list to hold the headers.\n",
    "    print('image.shape =', image.shape)\n",
    "\n",
    "    for i in range(len(files)):\n",
    "\n",
    "    # ########################################################################   \n",
    "        # Use this code block if you want to work with DataFits objects\n",
    "        df = DataFits() \n",
    "        df.load(os.path.join(whichpath,files[i]))\n",
    "        image[i] = df.imageget() * 1.0            # Load image data into numpy arrays and convert to float.\n",
    "        headlist.append(df.header)\n",
    "        imedian[i] = np.nanmedian(image[i])\n",
    "        imad[i] = mad_std(image[i],ignore_nan=True)\n",
    "        print('')\n",
    "        print(i, files[i])\n",
    "    # #########################################################################\n",
    "\n",
    "    #############################################################################\n",
    "    #     # Use this code block if you want to use the standard astropy.io package.\n",
    "    #     fitsfilename = os.path.join(datapath, files[i])    # Full path to a fitsfile.\n",
    "    #     hdulist = fits.open(fitsfilename)                  # Open a fits file as an hdulist object.\n",
    "    #     hdu0 = hdulist[0]                                  # Define a fits object as the 0th hdu in the fitsfile.\n",
    "    #     image[i] = hdu0.data * 1.0                         # Define image in stack as float of data in the 0th hdu.\n",
    "    #     headlist.append(hdu0.header)                       # Append the header of the fits object to the header list.\n",
    "    #     print('')\n",
    "    #     print(i,files[i])\n",
    "    ###############################################################################   \n",
    "    return image, headlist, rows, cols, imedian, imad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbimage, nbheadlist, nbrows, nbcols, nbimedian, nbimad = stackfits(datapath,allfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is very important\n",
    "\n",
    "bstackarray = nbimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze the variation of each pixel in the stack\n",
    "\n",
    "bstackarray_std = np.std(bstackarray, axis=0)\n",
    "\n",
    "bimg_global_std = np.median(bstackarray_std)\n",
    "\n",
    "bnoisy_pixels = bstackarray_std > bimg_global_std*1.8\n",
    "\n",
    "#we identified the pixels across the bias exposures whose values deviate from their respective means by 1.8 standard deviations\n",
    "# this threshold was chosen based on visual comparisons with 1.7 standev and 1.9 standev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify and list the pixels that exceed the noise threshold\n",
    "\n",
    "## plt.imshow(noisy_pixels)\n",
    "\n",
    "blocs = np.array(np.where(bnoisy_pixels == True))\n",
    "nbpix_bias = np.zeros((1019,1019)) \n",
    "for i in range(1019): #1024\n",
    "    for j in range(1019): #1024\n",
    "        if bnoisy_pixels[i,j] == True and j > 5:\n",
    "            nbpix_bias[i,j] = 1\n",
    "            \n",
    "\n",
    "# for i in range(locs.shape[1]):\n",
    "#     print(locs[0,i],locs[1,i])\n",
    "    \n",
    "#this prints a list of noisy pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we repeat the process for 020s\n",
    "##This can be applied to any subset of raw fits images.\n",
    "##In this example we used a single data set subdivided into exposure types\n",
    "\n",
    "somefiles = [f for f in os.listdir(whichpath) if '.fit' in f and '_020s' in f and'stack' not in f]\n",
    "\n",
    "somefiles = sorted(somefiles)       ## This is necessary on my Mac, may not be for others?\n",
    "\n",
    "\n",
    "acceptlist = True             # True if you want to accept all the files in somefiles.\n",
    "contiguous = True             # True if you want to accept a contiguous subset of somefiles.\n",
    "startfile, endfile = 5,9      # The first and last files in a contiquous subset.\n",
    "flist = [0,3,4,5,6,7,8]        # An explicit list of the files you want to accept.\n",
    "\n",
    "n20image, n20headlist, n20rows, n20cols, n20imedian, n20imad = stackfits(datapath,somefiles)\n",
    "\n",
    "\n",
    "n20stackarray = n20image\n",
    "\n",
    "n20stackarray_std = np.std(n20stackarray, axis=0)\n",
    "\n",
    "n20img_global_std = np.median(n20stackarray_std)\n",
    "\n",
    "n20noisy_pixels = n20stackarray_std > n20img_global_std*1.8\n",
    "\n",
    "\n",
    "n20locs = np.array(np.where(n20noisy_pixels == True))\n",
    "npix_020s = np.zeros((1019,1019)) \n",
    "for i in range(1019): #1024\n",
    "    for j in range(1019): #1024\n",
    "        if n20noisy_pixels[i,j] == True and j > 5:\n",
    "            npix_020s[i,j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we repeat the process for 040s\n",
    "##This can be applied to any subset of raw fits images.\n",
    "##In this example we used a single data set subdivided into exposure types\n",
    "\n",
    "somefiles = [f for f in os.listdir(whichpath) if '.fit' in f and '_040s' in f and'stack' not in f]\n",
    "\n",
    "somefiles = sorted(somefiles)       ## This is necessary on my Mac, may not be for others?\n",
    "\n",
    "\n",
    "acceptlist = True             # True if you want to accept all the files in somefiles.\n",
    "contiguous = True             # True if you want to accept a contiguous subset of somefiles.\n",
    "startfile, endfile = 5,9      # The first and last files in a contiquous subset.\n",
    "flist = [0,3,4,5,6,7,8]        # An explicit list of the files you want to accept.\n",
    "\n",
    "n40image, n40headlist, n40rows, n40cols, n40imedian, n40imad = stackfits(datapath,somefiles)\n",
    "\n",
    "\n",
    "n40stackarray = n40image\n",
    "\n",
    "n40stackarray_std = np.std(n40stackarray, axis=0)\n",
    "\n",
    "n40img_global_std = np.median(n40stackarray_std)\n",
    "\n",
    "n40noisy_pixels = n40stackarray_std > n40img_global_std*1.8\n",
    "\n",
    "\n",
    "n40locs = np.array(np.where(n40noisy_pixels == True))\n",
    "npix_040s = np.zeros((1019,1019)) \n",
    "for i in range(1019): #1024\n",
    "    for j in range(1019): #1024\n",
    "        if n40noisy_pixels[i,j] == True and j > 5:\n",
    "            npix_040s[i,j] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we repeat the process for 100s\n",
    "##This can be applied to any subset of raw fits images.\n",
    "##In this example we used a single data set subdivided into exposure types\n",
    "\n",
    "somefiles = [f for f in os.listdir(whichpath) if '.fit' in f and '_100s' in f and'stack' not in f]\n",
    "\n",
    "somefiles = sorted(somefiles)       ## This is necessary on my Mac, may not be for others?\n",
    "\n",
    "\n",
    "acceptlist = True             # True if you want to accept all the files in somefiles.\n",
    "contiguous = True             # True if you want to accept a contiguous subset of somefiles.\n",
    "startfile, endfile = 5,9      # The first and last files in a contiquous subset.\n",
    "flist = [0,3,4,5,6,7,8]        # An explicit list of the files you want to accept.\n",
    "\n",
    "n100image, n100headlist, n100rows, n100cols, n100imedian, n100imad = stackfits(datapath,somefiles)\n",
    "\n",
    "\n",
    "n100stackarray = n100image\n",
    "\n",
    "n100stackarray_std = np.std(n100stackarray, axis=0)\n",
    "\n",
    "n100img_global_std = np.median(n100stackarray_std)\n",
    "\n",
    "n100noisy_pixels = n100stackarray_std > n100img_global_std*1.8\n",
    "\n",
    "\n",
    "n100locs = np.array(np.where(n100noisy_pixels == True))\n",
    "npix_100s = np.zeros((1019,1019)) \n",
    "for i in range(1019): #1024\n",
    "    for j in range(1019): #1024\n",
    "        if n100noisy_pixels[i,j] == True and j > 5:\n",
    "            npix_100s[i,j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we repeat the process for 0180s\n",
    "##This can be applied to any subset of raw fits images.\n",
    "##In this example we used a single data set subdivided into exposure types\n",
    "\n",
    "somefiles = [f for f in os.listdir(whichpath) if '.fit' in f and '_180s' in f and'stack' not in f]\n",
    "\n",
    "somefiles = sorted(somefiles)       ## This is necessary on my Mac, may not be for others?\n",
    "\n",
    "\n",
    "acceptlist = True             # True if you want to accept all the files in somefiles.\n",
    "contiguous = True             # True if you want to accept a contiguous subset of somefiles.\n",
    "startfile, endfile = 5,9      # The first and last files in a contiquous subset.\n",
    "flist = [0,3,4,5,6,7,8]        # An explicit list of the files you want to accept.\n",
    "\n",
    "n180image, n180headlist, n180rows, n180cols, n180imedian, n180imad = stackfits(datapath,somefiles)\n",
    "\n",
    "\n",
    "n180stackarray = n180image\n",
    "\n",
    "n180stackarray_std = np.std(n180stackarray, axis=0)\n",
    "\n",
    "n180img_global_std = np.median(n180stackarray_std)\n",
    "\n",
    "n180noisy_pixels = n180stackarray_std > n180img_global_std*1.8\n",
    "\n",
    "\n",
    "n180locs = np.array(np.where(n180noisy_pixels == True))\n",
    "npix_180s = np.zeros((1019,1019)) \n",
    "for i in range(1019): #1024\n",
    "    for j in range(1019): #1024\n",
    "        if n180noisy_pixels[i,j] == True and j > 5:\n",
    "            npix_180s[i,j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stack the arrays of noisy pixels\n",
    "\n",
    "dims = list(nbpix_bias.shape)\n",
    "dims.append(5)\n",
    "dims = [5,nbpix_bias.shape[0],nbpix_bias.shape[1]]\n",
    "npixm = np.zeros(dims)\n",
    "npixm[0,:,:]= nbpix_bias\n",
    "npixm[1,:,:]= npix_020s\n",
    "npixm[2,:,:]= npix_040s\n",
    "npixm[3,:,:]= npix_100s\n",
    "npixm[4,:,:]= npix_180s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a workable data format for our boolean 2D Array\n",
    "hdumy = fits.PrimaryHDU(npixm)\n",
    "\n",
    "#Turning Workable Object into a fits\n",
    "outd = fits.HDUList([hdumy])\n",
    "\n",
    "## Construct a name and 'save directory' for the dark-subtracted, flatfielded image.\n",
    "outname = 'noisy_pixels' + '(INSERT NUMBER OR OTHER THING!!!!! OR ITLL BREAK SOME STUFF) 1' + '.fits'\n",
    "outpath = savepath\n",
    "print('outpath =',outpath)\n",
    "outf = os.path.join(outpath,outname)\n",
    "print('outname =',outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now save the file (or not).\n",
    "print(outf)\n",
    "yes_or_no = input('Save file? Enter \"y\" or \"n\":')\n",
    "if yes_or_no == 'y':\n",
    "    outd.writeto(outf, overwrite = False)\n",
    "    print( outname + ' has been saved.')\n",
    "else:\n",
    "    print( 'OK-- file was not saved.')\n",
    "\n",
    "# outd.save(outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
