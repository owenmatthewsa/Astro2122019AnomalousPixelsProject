{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports. This contains some imports not required for this notebook. \n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import pylab                   # Needed to plot histograms.\n",
    "from astropy.io import fits                    # Need this if you want to use astropy.io io objects.\n",
    "from astropy.stats import mad_std              # The median absolute deviation, a more robust estimator than std.\n",
    "from PIL import Image\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import signal\n",
    "\n",
    "'''Filter out warnings. May or may not need this. But shouldn't hurt to put it in.\n",
    "This is the \"new\" code for avoiding warnings-- seems to work better. Copied from an SDSS notebook.'''\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append(r'C:\\Users\\owenm\\Documents\\ASTR 21200 2019\\Software\\a212pylibs\\datapype')\n",
    "\n",
    "from datafits import DataFits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the data directory.\n",
    "datapath = r'C:\\Users\\owenm\\Documents\\ASTR 21200 2019\\Data\\Project\\Last'\n",
    "savepath = r'C:\\Users\\owenm\\Documents\\ASTR 21200 2019\\Data\\BadPixelsFitss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List files in the the data directory.\n",
    "\n",
    "whichpath = datapath\n",
    "\n",
    "## For ALL the files in the directory.\n",
    "# allfiles = [f for f in os.listdir(datapath)]\n",
    "\n",
    "exposures = ['bias','020s', '040s', '100s', '180s']\n",
    "allfiles = [0] * 5\n",
    "\n",
    "## Various list comprehensions can pick out files with particular characteristics.\n",
    "for i,exposure in enumerate(exposures):\n",
    "    allfiles[i] = [f for f in os.listdir(whichpath) if '.fit' in f and (exposure in f) and 'mdark' not in f]\n",
    "\n",
    "for i in range(len(exposures)):    \n",
    "    allfiles[i] = sorted(allfiles[i])       ## This is necessary on my Mac, may not be for others?\n",
    "    for j in range(len(allfiles[i])):\n",
    "        print(j, allfiles[i][j])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct a list of files you wish to view and/or process.\n",
    "\n",
    "acceptlist = True             # True if you want to accept all the files in allfiles.\n",
    "contiguous = True             # True if you want to accept a contiguous subset of allfiles.\n",
    "startfile, endfile = 0,9      # The first and last files in a contiquous subset.\n",
    "flist = [0,3,4,5,6,7,8]        # An explicit list of the files you want to accept.\n",
    "files = [0] * 5\n",
    "\n",
    "if acceptlist == True:\n",
    "    for i in range(len(files)):\n",
    "        files[i] = allfiles[i]\n",
    "        for j in range(len(files[i])):\n",
    "            print(j, files[i][j])\n",
    "else:\n",
    "    if contiguous == True:\n",
    "        for i in range(len(files)):\n",
    "            files[i] = allfiles[i][startfile:endfile+1]\n",
    "            for j in range(len(files[i])):\n",
    "                print(j, files[i][j])\n",
    "    else:\n",
    "        #files = []\n",
    "        for i in range(len(files)):\n",
    "            for j in range(len(flist)):\n",
    "                files[i].append(allfiles[flist[j]])\n",
    "            for j in range(len(files[i])):\n",
    "                print(j, flist[j], files[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1. Creating Faulty Non-Noisy Pixels Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Make a stack of images, a list of headers from those images, and calculate some medians and stds\n",
    "that will help set autoscaling parameters.'''\n",
    "\n",
    "\n",
    "image = [0] * 5\n",
    "imedian = [0] * 5\n",
    "istd = [0] * 5\n",
    "madstd = [0] * 5\n",
    "headlist = [''] * 5\n",
    "for i in range(5):\n",
    "    image[i] = np.zeros((len(files[i]), 1024,1024))\n",
    "    imedian[i] = np.zeros((len(files[i])))          \n",
    "    istd[i] = np.zeros((len(files[i])))              \n",
    "    madstd[i] = np.zeros((len(files[i]))) \n",
    "    headlist[i] = []  \n",
    "    print('image.shape =', image[i].shape)\n",
    "    for j in range(len(files[i])):\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "    # Use this code block if you want to use the standard astropy.io package.\n",
    "        fitsfilename = os.path.join(datapath, files[i][j])    # Full path to a fitsfile.\n",
    "        hdulist = fits.open(fitsfilename)                  # Open a fits file as an hdulist object.\n",
    "        hdu0 = hdulist[0]                                  # Define a fits object as the 0th hdu in the fitsfile.\n",
    "        image[i][j] = hdu0.data * 1.0                         # Define image in stack as float of data in the 0th hdu.\n",
    "        headlist.append(hdu0.header)                       # Append the header of the fits object to the header list.\n",
    "        print('')\n",
    "        print(j,files[i][j])\n",
    "###############################################################################    \n",
    "    \n",
    "    ## Calculate some medians and stds to use in autoscaling that aren't unduly biased by extreme values.\n",
    "    ## Optionally, print out masked and unmasked values to explore the effects of extreme values on the statistics.\n",
    "    \n",
    "        madstd[i][j] = mad_std(image[i][j],ignore_nan=True)\n",
    "        imedian[i][j] = np.nanmedian(image[i][j])\n",
    "        istd[i][j] = np.nanstd(image[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a map of how often the pixels have been bad\n",
    "\n",
    "bads = [0] * 5\n",
    "imedian2 = [0] * 5\n",
    "istd2 = [0] * 5\n",
    "b = [0] * 5\n",
    "pix = [0] * 5\n",
    "ctr = [0] * 5\n",
    "for i in range(5):\n",
    "    bads[i] = np.zeros((1024,1024))\n",
    "\n",
    "    imedian2[i] = np.zeros((len(files[i])))           # 1D numpy array to hold array medians.\n",
    "    istd2[i] = np.zeros((len(files[i])))              # 1D numpy array to hold array stds.\n",
    "\n",
    "    for j in range(len(files[i])):\n",
    "        imedian2[i][j] = np.nanmedian(image[i][j,200:,:])\n",
    "        istd2[i][j] = np.nanstd(image[i][j,200:,:])\n",
    "        #sets the median and std arrays to hold the median and std of each image\n",
    "\n",
    "    for j in range(len(image[i])):\n",
    "        istand = image[i][j] - imedian2[i][j]\n",
    "        bad1 = (istand > istd2[i][j]) * 1\n",
    "        #check if 1 standard deviation above the median\n",
    "        bad2 = (istand < -istd2[i][j]) * 1\n",
    "        #check if 1 standard deviation below the median\n",
    "        bad = bad1 + bad2\n",
    "        #will be 1 if one standard deviation off (above or below), 0 otherwise\n",
    "        bads[i] += bad\n",
    "    #counts the number\n",
    "\n",
    "    #print(bads)\n",
    "    #print(bads[:,1:])\n",
    "    b[i] = bads[i][:, 200:]\n",
    "    print(b[i])\n",
    "    pix[i] = np.zeros((1024,824))\n",
    "    #ctr = 0\n",
    "    for j in range(1024):\n",
    "        for k in range(824):\n",
    "            if b[i][j,k] >= len(files[i]) * 0.6:\n",
    "                ctr[i] += 1\n",
    "                pix[i][j,k] = 1\n",
    "                #print(j,k)\n",
    "    #checks number of images for which a pixel is in \"bads\"\n",
    "    #if  >20 times bad, sets the pixel's corresponding point in \"pix\" to 1\n",
    "\n",
    "    print(str(ctr[i]/(1024 * 824)))\n",
    "#gives ratio of flaged pixels to all pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above array gives the number of times, for each pixel, it has been deemed \"bad\" in the list of 300 darks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check pixels that have been bad at least once: 49.2% of pixels meet this criteria If we check pixels that have been bad at least twice: 18.5% of pixels meet this criteria If we check pixels that have been bad at least 3 times: 8.28% of pixels meet this criteria If we check pixels that have been bad at least 4 times: 5.21% of pixels meet this criteria ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code makes list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pix3 = [0] * 5\n",
    "mask3 = [0] * 5\n",
    "for i in range(5):\n",
    "    pix3[i] = np.zeros((1024,824))\n",
    "    #makes 2D a zero array that will become our final list of pixels to smooth over\n",
    "    mask3[i] = np.zeros((len(files[i]),1024,824))\n",
    "    #zero array that will become a stack of masks\n",
    "    for j in range(1024):\n",
    "        for k in range(824):\n",
    "            if pix[i][j,k] == 1:\n",
    "            #checks if pixel has been flagged by first algorithm, ignore if not\n",
    "            #this next series of if statements considers several different possible pixel locations, with the goal of setting a \"sur\"\n",
    "            #\"sur\" is a 2D array that is basically the pixel values of the surronding area\n",
    "                if j >= 5 and j < 1019:\n",
    "                    #all of these use a row value between 5 and 1019\n",
    "                    if k >= 5 and k < 819:\n",
    "                        sur = image[i][:,j-5:j+5,200+k-5:200+k+5]\n",
    "                        #these pixels are in places where we can easily check the surronding area\n",
    "                    elif k < 5:\n",
    "                        sur = np.append(image[i][:,j-5:j+5,200:200+k], image[i][:,j-5:j+5,-10+k:])\n",
    "                        #if in a colum <5, wraps around the side to fill in the rest of the neighborhood\n",
    "                    else:\n",
    "                        sur = np.append(image[i][:,j-5:j+5,k:], image[i][:,j-5:j+5,200:210-1024+k])\n",
    "                        #column in last 5, wraps around to fill in rest of neighborhood\n",
    "                elif j < 5:\n",
    "                    #all of these are for a row value less than 5\n",
    "                    if k >= 5 and k < 819:\n",
    "                        sur = np.append(image[i][:,:j,200+k-5:200+k+5], image[i][:,-10+j:,200+k-5:200+k+5])\n",
    "                        #accaptable column value, only need to wrap around top-bottom (rows)\n",
    "                    elif k < 5:\n",
    "                        sur = np.append(image[i][:,:j,200:200+k], image[i][:,-10+j:,-10+k:])\n",
    "                        #in a corner, wraps around to fill in both dimensions\n",
    "                    else:\n",
    "                        sur = np.append(image[i][:,:j,k:], image[i][:,-10+j:,200:210-1024+k])\n",
    "                        #second corner\n",
    "                else:\n",
    "                    #row values in the last 5\n",
    "                    if k >= 5 and k < 819:\n",
    "                        sur = np.append(image[i][:,j:,200+k-5:200+k+5], image[i][:, :10-1024+j,200+k-5:200+k+5])\n",
    "                        #accaptable column value, only need to wrap around top-bottom (rows)\n",
    "                    elif k < 5:\n",
    "                        sur = np.append(image[i][:,j:,200:200+k], image[i][:, :10-1024+j,-10+k:])\n",
    "                        #third corner, wrap around in both dimensions\n",
    "                    else:\n",
    "                        sur = np.append(image[i][:,j:,k:], image[i][:, :10-1024+j,200:210-1024+k])\n",
    "                        #fourth corner\n",
    "                surmed = np.nanmedian(sur)\n",
    "                #sets surmed to median value of the surronding area\n",
    "                surstd = np.nanstd(sur)\n",
    "                #sets surstd to standard deviation of surronding area\n",
    "                pmed = np.nanmedian(image[i][:,j,200+k])\n",
    "                #finds the median value of the pixel accross all 32 images\n",
    "                pix3[i][j,k] = abs(surmed - pmed) > surstd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stack the arrays of noisy pixels\n",
    "\n",
    "fbpix = np.zeros((5,1024,1024))\n",
    "\n",
    "pixhelp2 = np.zeros((1024,200))\n",
    "for i in range(5):\n",
    "    fbpix[i,:,:] = np.append(pixhelp2,pix3[i], axis=1)\n",
    "\n",
    "\n",
    "dims = [5,1024,1024]\n",
    "dpixm = np.zeros(dims)\n",
    "dpixm[0,:,:]= fbpix[0,:,:]\n",
    "dpixm[1,:,:]= fbpix[1,:,:]\n",
    "dpixm[2,:,:]= fbpix[2,:,:]\n",
    "dpixm[3,:,:]= fbpix[3,:,:]\n",
    "dpixm[4,:,:]= fbpix[4,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a workable data format for our boolean 2D Array\n",
    "hdumy = fits.PrimaryHDU(dpixm)\n",
    "\n",
    "#Turning Workable Object into a fits\n",
    "outd = fits.HDUList([hdumy])\n",
    "\n",
    "## Construct a name and 'save directory' for the dark-subtracted, flatfielded image.\n",
    "outname = 'dead_pixels' + 'test1 ' + '.fits'\n",
    "outpath = savepath\n",
    "print('outpath =',outpath)\n",
    "outf = os.path.join(outpath,outname)\n",
    "print('outname =',outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now save the file (or not).\n",
    "print(outf)\n",
    "yes_or_no = input('Save file? Enter \"y\" or \"n\":')\n",
    "if yes_or_no == 'y':\n",
    "    outd.writeto(outf, overwrite = False)\n",
    "    print( outname + ' has been saved.')\n",
    "else:\n",
    "    print( 'OK-- file was not saved.')\n",
    "\n",
    "# outd.save(outf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a median dark image from the image stack\n",
    "dark = np.nanmedian(image, axis=0)\n",
    "# make a bias file\n",
    "bias = dark.copy()\n",
    "\n",
    "# take a median row slice and smooth it\n",
    "rowslice = np.median(bias, axis=0)\n",
    "# smooth_rowslice = signal.medfilt(rowslice, kernel_size=5)\n",
    "# smooth_rowslice = signal.savgol_filter(smooth_rowslice, window_length=101, polyorder=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making initial mask\n",
    "for i in range(1024):\n",
    "    for j in range(824):          \n",
    "            # sets to 1 if the median pixel value is more than one standard deviation away from the median of the surronding area\n",
    "            if pix3[i,j] == 1:\n",
    "                mask3[:,i,j] = image[:,i,200+j] - rowslice[200+j]\n",
    "                #if pix3 is 1, sets the mask to be the value of the original image minus that value of the neighborhood median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masking for pix3 \n",
    "\n",
    "maskhelp2 = np.zeros((len(files),1024,200))\n",
    "mask6 = np.append(maskhelp2,mask3, axis=2)\n",
    "\n",
    "smoothed3 = image-mask6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating and saving dead pixels fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a workable data format for our boolean 2D Array\n",
    "hdumy = fits.PrimaryHDU(pix3)\n",
    "\n",
    "#Turning Workable Object into a fits\n",
    "outd = fits.HDUList([hdumy])\n",
    "\n",
    "## Construct a name and 'save directory' for the dark-subtracted, flatfielded image.\n",
    "outname = 'bad_pixels' + '(INSERT NUMBER OR OTHER THING!!!!! OR ITLL BREAK SOME STUFF) 5' + '.fits'\n",
    "outpath = savepath\n",
    "print('outpath =',outpath)\n",
    "outf = os.path.join(outpath,outname)\n",
    "print('outname =',outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now save the file (or not).\n",
    "print(outf)\n",
    "yes_or_no = input('Save file? Enter \"y\" or \"n\":')\n",
    "if yes_or_no == 'y':\n",
    "    outd.writeto(outf, overwrite = False)\n",
    "    print( outname + ' has been saved.')\n",
    "else:\n",
    "    print( 'OK-- file was not saved.')\n",
    "\n",
    "# outd.save(outf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 Creating Fits of Noisy Pixels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List files in the the data directory.\n",
    "\n",
    "whichpath = datapath\n",
    "\n",
    "## For ALL the files in the directory.\n",
    "# allfiles = [f for f in os.listdir(datapath)]\n",
    "\n",
    "## Various list comprehensions can pick out files with particular characteristics.\n",
    "allfiles = [f for f in os.listdir(whichpath) if '.fit' in f and ('bias.' in f) and 'mdark' not in f]\n",
    "\n",
    "allfiles = sorted(allfiles)       ## This is necessary on my Mac, may not be for others?\n",
    "for i in range(len(allfiles)):\n",
    "    print( i, allfiles[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct a list of files you wish to view and/or process.\n",
    "\n",
    "acceptlist = True             # True if you want to accept all the files in allfiles.\n",
    "contiguous = True             # True if you want to accept a contiguous subset of allfiles.\n",
    "startfile, endfile = 0,9      # The first and last files in a contiquous subset.\n",
    "flist = [0,3,4,5,6,7,8]        # An explicit list of the files you want to accept.\n",
    "\n",
    "if acceptlist == True:\n",
    "    files = allfiles\n",
    "    for i in range(len(files)):\n",
    "        print(i, files[i])\n",
    "else:\n",
    "    if contiguous == True:\n",
    "        files = allfiles[startfile:endfile+1]\n",
    "        for i in range(len(files)):\n",
    "            print( i, files[i])\n",
    "    else:\n",
    "        files = []\n",
    "        for i in range(len(flist)):\n",
    "            files.append(allfiles[flist[i]])\n",
    "        for i in range(len(files)):\n",
    "            print( i, flist[i], files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In dah_functions2 but my imports are being weird so i did it.\n",
    "def stackfits(whichpath,files):\n",
    "    '''\n",
    "    Make a stack of images, a list of headers from those images, and 1D arrays for medians and mad_stds.\n",
    "    whichpath:   The path to the fits files.\n",
    "    files:  A list of files.\n",
    "    '''\n",
    "\n",
    "    ## Load the header of the first file in the list \"files\".\n",
    "    df = DataFits()                                                   # Create a DataPype DataFits io object.\n",
    "    df.loadhead(os.path.join(whichpath,files[0]))                # Loads just the header of the first file.\n",
    "    ## Make variables for the numbers of rows and columns.\n",
    "    rows, cols = df.header['naxis2'], df.header['naxis1']\n",
    "    print('rows =',rows,'   cols =',cols)\n",
    "\n",
    "    image = np.zeros((len(files), rows,cols))  # 3D numpy array to hold the stack of images.\n",
    "    imedian = np.zeros((len(files)))           # 1D numpy array to hold array medians.\n",
    "    imad = np.zeros((len(files)))            # 1D numpy array to hold Median absolute deviations.\n",
    "\n",
    "    headlist = []                              # Empty list to hold the headers.\n",
    "    print('image.shape =', image.shape)\n",
    "\n",
    "    for i in range(len(files)):\n",
    "\n",
    "    # ########################################################################   \n",
    "        # Use this code block if you want to work with DataFits objects\n",
    "        df = DataFits() \n",
    "        df.load(os.path.join(whichpath,files[i]))\n",
    "        image[i] = df.imageget() * 1.0            # Load image data into numpy arrays and convert to float.\n",
    "        headlist.append(df.header)\n",
    "        imedian[i] = np.nanmedian(image[i])\n",
    "        imad[i] = mad_std(image[i],ignore_nan=True)\n",
    "        print('')\n",
    "        print(i, files[i])\n",
    "    # #########################################################################\n",
    "\n",
    "    #############################################################################\n",
    "    #     # Use this code block if you want to use the standard astropy.io package.\n",
    "    #     fitsfilename = os.path.join(datapath, files[i])    # Full path to a fitsfile.\n",
    "    #     hdulist = fits.open(fitsfilename)                  # Open a fits file as an hdulist object.\n",
    "    #     hdu0 = hdulist[0]                                  # Define a fits object as the 0th hdu in the fitsfile.\n",
    "    #     image[i] = hdu0.data * 1.0                         # Define image in stack as float of data in the 0th hdu.\n",
    "    #     headlist.append(hdu0.header)                       # Append the header of the fits object to the header list.\n",
    "    #     print('')\n",
    "    #     print(i,files[i])\n",
    "    ###############################################################################   \n",
    "    return image, headlist, rows, cols, imedian, imad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbimage, nbheadlist, nbrows, nbcols, nbimedian, nbimad = stackfits(datapath,allfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is very important\n",
    "\n",
    "bstackarray = nbimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze the variation of each pixel in the stack\n",
    "\n",
    "bstackarray_std = np.std(bstackarray, axis=0)\n",
    "\n",
    "bimg_global_std = np.median(bstackarray_std)\n",
    "\n",
    "bnoisy_pixels = bstackarray_std > bimg_global_std*1.8\n",
    "\n",
    "#we identified the pixels across the bias exposures whose values deviate from their respective means by 1.8 standard deviations\n",
    "# this threshold was chosen based on visual comparisons with 1.7 standev and 1.9 standev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify and list the pixels that exceed the noise threshold\n",
    "\n",
    "## plt.imshow(noisy_pixels)\n",
    "\n",
    "blocs = np.array(np.where(bnoisy_pixels == True))\n",
    "nbpix_bias = np.zeros((1019,1019)) \n",
    "for i in range(1019): #1024\n",
    "    for j in range(1019): #1024\n",
    "        if bnoisy_pixels[i,j] == True and j > 5:\n",
    "            nbpix_bias[i,j] = 1\n",
    "            \n",
    "\n",
    "# for i in range(locs.shape[1]):\n",
    "#     print(locs[0,i],locs[1,i])\n",
    "    \n",
    "#this prints a list of noisy pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we repeat the process for 020s\n",
    "##This can be applied to any subset of raw fits images.\n",
    "##In this example we used a single data set subdivided into exposure types\n",
    "\n",
    "somefiles = [f for f in os.listdir(whichpath) if '.fit' in f and '_020s' in f and'stack' not in f]\n",
    "\n",
    "somefiles = sorted(somefiles)       ## This is necessary on my Mac, may not be for others?\n",
    "\n",
    "\n",
    "acceptlist = True             # True if you want to accept all the files in somefiles.\n",
    "contiguous = True             # True if you want to accept a contiguous subset of somefiles.\n",
    "startfile, endfile = 5,9      # The first and last files in a contiquous subset.\n",
    "flist = [0,3,4,5,6,7,8]        # An explicit list of the files you want to accept.\n",
    "\n",
    "n20image, n20headlist, n20rows, n20cols, n20imedian, n20imad = stackfits(datapath,somefiles)\n",
    "\n",
    "\n",
    "n20stackarray = n20image\n",
    "\n",
    "n20stackarray_std = np.std(n20stackarray, axis=0)\n",
    "\n",
    "n20img_global_std = np.median(n20stackarray_std)\n",
    "\n",
    "n20noisy_pixels = n20stackarray_std > n20img_global_std*1.8\n",
    "\n",
    "\n",
    "n20locs = np.array(np.where(n20noisy_pixels == True))\n",
    "npix_020s = np.zeros((1024,1024)) \n",
    "for i in range(1024): \n",
    "    for j in range(1024): \n",
    "        if n20noisy_pixels[i,j] == True and j > 5:\n",
    "            npix_020s[i,j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we repeat the process for 040s\n",
    "##This can be applied to any subset of raw fits images.\n",
    "##In this example we used a single data set subdivided into exposure types\n",
    "\n",
    "somefiles = [f for f in os.listdir(whichpath) if '.fit' in f and '_040s' in f and'stack' not in f]\n",
    "\n",
    "somefiles = sorted(somefiles)       ## This is necessary on my Mac, may not be for others?\n",
    "\n",
    "\n",
    "acceptlist = True             # True if you want to accept all the files in somefiles.\n",
    "contiguous = True             # True if you want to accept a contiguous subset of somefiles.\n",
    "startfile, endfile = 5,9      # The first and last files in a contiquous subset.\n",
    "flist = [0,3,4,5,6,7,8]        # An explicit list of the files you want to accept.\n",
    "\n",
    "n40image, n40headlist, n40rows, n40cols, n40imedian, n40imad = stackfits(datapath,somefiles)\n",
    "\n",
    "\n",
    "n40stackarray = n40image\n",
    "\n",
    "n40stackarray_std = np.std(n40stackarray, axis=0)\n",
    "\n",
    "n40img_global_std = np.median(n40stackarray_std)\n",
    "\n",
    "n40noisy_pixels = n40stackarray_std > n40img_global_std*1.8\n",
    "\n",
    "\n",
    "n40locs = np.array(np.where(n40noisy_pixels == True))\n",
    "npix_040s = np.zeros((1024,1024)) \n",
    "for i in range(1024):\n",
    "    for j in range(1024):\n",
    "        if n40noisy_pixels[i,j] == True and j > 5:\n",
    "            npix_040s[i,j] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we repeat the process for 100s\n",
    "##This can be applied to any subset of raw fits images.\n",
    "##In this example we used a single data set subdivided into exposure types\n",
    "\n",
    "somefiles = [f for f in os.listdir(whichpath) if '.fit' in f and '_100s' in f and'stack' not in f]\n",
    "\n",
    "somefiles = sorted(somefiles)       ## This is necessary on my Mac, may not be for others?\n",
    "\n",
    "\n",
    "acceptlist = True             # True if you want to accept all the files in somefiles.\n",
    "contiguous = True             # True if you want to accept a contiguous subset of somefiles.\n",
    "startfile, endfile = 5,9      # The first and last files in a contiquous subset.\n",
    "flist = [0,3,4,5,6,7,8]        # An explicit list of the files you want to accept.\n",
    "\n",
    "n100image, n100headlist, n100rows, n100cols, n100imedian, n100imad = stackfits(datapath,somefiles)\n",
    "\n",
    "\n",
    "n100stackarray = n100image\n",
    "\n",
    "n100stackarray_std = np.std(n100stackarray, axis=0)\n",
    "\n",
    "n100img_global_std = np.median(n100stackarray_std)\n",
    "\n",
    "n100noisy_pixels = n100stackarray_std > n100img_global_std*1.8\n",
    "\n",
    "\n",
    "n100locs = np.array(np.where(n100noisy_pixels == True))\n",
    "npix_100s = np.zeros((1019,1019)) \n",
    "for i in range(1024):\n",
    "    for j in range(1024): \n",
    "        if n100noisy_pixels[i,j] == True and j > 5:\n",
    "            npix_100s[i,j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we repeat the process for 0180s\n",
    "##This can be applied to any subset of raw fits images.\n",
    "##In this example we used a single data set subdivided into exposure types\n",
    "\n",
    "somefiles = [f for f in os.listdir(whichpath) if '.fit' in f and '_180s' in f and'stack' not in f]\n",
    "\n",
    "somefiles = sorted(somefiles)       ## This is necessary on my Mac, may not be for others?\n",
    "\n",
    "\n",
    "acceptlist = True             # True if you want to accept all the files in somefiles.\n",
    "contiguous = True             # True if you want to accept a contiguous subset of somefiles.\n",
    "startfile, endfile = 5,9      # The first and last files in a contiquous subset.\n",
    "flist = [0,3,4,5,6,7,8]        # An explicit list of the files you want to accept.\n",
    "\n",
    "n180image, n180headlist, n180rows, n180cols, n180imedian, n180imad = stackfits(datapath,somefiles)\n",
    "\n",
    "\n",
    "n180stackarray = n180image\n",
    "\n",
    "n180stackarray_std = np.std(n180stackarray, axis=0)\n",
    "\n",
    "n180img_global_std = np.median(n180stackarray_std)\n",
    "\n",
    "n180noisy_pixels = n180stackarray_std > n180img_global_std*1.8\n",
    "\n",
    "\n",
    "n180locs = np.array(np.where(n180noisy_pixels == True))\n",
    "npix_180s = np.zeros((1024,1024)) \n",
    "for i in range(1024): \n",
    "    for j in range(1024): \n",
    "        if n180noisy_pixels[i,j] == True and j > 5:\n",
    "            npix_180s[i,j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stack the arrays of noisy pixels\n",
    "\n",
    "dims = list(nbpix_bias.shape)\n",
    "dims.append(5)\n",
    "dims = [5,nbpix_bias.shape[0],nbpix_bias.shape[1]]\n",
    "npixm = np.zeros(dims)\n",
    "npixm[0,:,:]= nbpix_bias\n",
    "npixm[1,:,:]= npix_020s\n",
    "npixm[2,:,:]= npix_040s\n",
    "npixm[3,:,:]= npix_100s\n",
    "npixm[4,:,:]= npix_180s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a workable data format for our boolean 2D Array\n",
    "hdumy = fits.PrimaryHDU(npixm)\n",
    "\n",
    "#Turning Workable Object into a fits\n",
    "outd = fits.HDUList([hdumy])\n",
    "\n",
    "## Construct a name and 'save directory' for the dark-subtracted, flatfielded image.\n",
    "outname = 'noisy_pixels' + '(INSERT NUMBER OR OTHER THING!!!!! OR ITLL BREAK SOME STUFF) 1' + '.fits'\n",
    "outpath = savepath\n",
    "print('outpath =',outpath)\n",
    "outf = os.path.join(outpath,outname)\n",
    "print('outname =',outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now save the file (or not).\n",
    "print(outf)\n",
    "yes_or_no = input('Save file? Enter \"y\" or \"n\":')\n",
    "if yes_or_no == 'y':\n",
    "    outd.writeto(outf, overwrite = False)\n",
    "    print( outname + ' has been saved.')\n",
    "else:\n",
    "    print( 'OK-- file was not saved.')\n",
    "\n",
    "# outd.save(outf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 Combining all of the noise and bad files list and adding shifting them over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath2 = r'C:\\Users\\owenm\\Documents\\ASTR 21200 2019\\Data\\BadPixelsFitss'\n",
    "savepath2 = r'C:\\Users\\owenm\\Documents\\ASTR 21200 2019\\Data\\master'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List files in the the data directory.\n",
    "\n",
    "whichpath = datapath2\n",
    "\n",
    "## For ALL the files in the directory.\n",
    "# allfiles = [f for f in os.listdir(datapath)]\n",
    "\n",
    "## Various list comprehensions can pick out files with particular characteristics.\n",
    "allfiles = [f for f in os.listdir(whichpath) if 'master' in f]\n",
    "\n",
    "allfiles = sorted(allfiles)       ## This is necessary on my Mac, may not be for others?\n",
    "for i in range(len(allfiles)):\n",
    "    print( i, allfiles[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct a list of files you wish to view and/or process.\n",
    "\n",
    "acceptlist = True             # True if you want to accept all the files in allfiles.\n",
    "contiguous = True             # True if you want to accept a contiguous subset of allfiles.\n",
    "startfile, endfile = 0,9      # The first and last files in a contiquous subset.\n",
    "flist = [0,3,4,5,6,7,8]        # An explicit list of the files you want to accept.\n",
    "\n",
    "if acceptlist == True:\n",
    "    files = allfiles\n",
    "    for i in range(len(files)):\n",
    "        print(i, files[i])\n",
    "else:\n",
    "    if contiguous == True:\n",
    "        files = allfiles[startfile:endfile+1]\n",
    "        for i in range(len(files)):\n",
    "            print( i, files[i])\n",
    "    else:\n",
    "        files = []\n",
    "        for i in range(len(flist)):\n",
    "            files.append(allfiles[flist[i]])\n",
    "        for i in range(len(files)):\n",
    "            print( i, flist[i], files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbiasimage = np.zeros((len(files),1024,1024))\n",
    "f20image = np.zeros((len(files),1024,1024))\n",
    "f40image = np.zeros((len(files),1024,1024))\n",
    "f100image = np.zeros((len(files),1024,1024))\n",
    "f180image = np.zeros((len(files),1024,1024))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(files)): \n",
    "    fitsfilename = os.path.join(datapath2, files[i])    \n",
    "    hdulist = fits.open(fitsfilename)     \n",
    "    hdubias = hdulist[0]  \n",
    "    hdu20 = hdulist[1] \n",
    "    hdu40 = hdulist[2] \n",
    "    hdu100 = hdulist[3] \n",
    "    hdu180 = hdulist[4] \n",
    "\n",
    "    fbiasimage[i] = hdubias.data * 1.0\n",
    "    f20image[i] = hdu20.data * 1.0\n",
    "    f40image[i] = hdu40.data * 1.0\n",
    "    f100image[i] = hdu100.data * 1.0\n",
    "    f180image[i] = hdu180.data * 1.0\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fimage = np.zeros(1024,1024)\n",
    "\n",
    "for i in range(len(files)): \n",
    "    fitsfilename = os.path.join(datapath2, files[i])    \n",
    "    hdulist = fits.open(fitsfilename)                  \n",
    "    hdubias = hdulist[0]  \n",
    "    hdu20 = hdulist[1] \n",
    "    hdu40 = hdulist[2] \n",
    "    hdu100 = hdulist[3] \n",
    "    hdu180 = hdulist[4] \n",
    "    \n",
    "    fimage[i] = hdubias.data * 1.0  + hdu20.data * 2.0 + hdu40.data * 3.0 + hdu100.data * 4.0 + hdu180.data *5.0                 \n",
    "                      \n",
    "fpix = np.zeros(1024,1024)\n",
    "for i in range(len(files))\n",
    "    fpix += fimage[i]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
